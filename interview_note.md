### [Python](#Python)
* [List](#list)
* [Dict](#dict)
* [什么是函数的参数](#函数的参数)
* [什么是高阶函数](#高阶函数)
* [什么是闭包](#闭包)
* [什么是装饰器](#装饰器)
* [什么是偏函数](#偏函数)
* [什么是迭代器](#迭代器)
* [什么是单例模式](#单例模式)
* [什么是多线程](#多线程)
* [什么是线程本地数据](#线程本地数据)
* [什么是多进程](#多进程)
* [什么是协程](#协程)

### [Spider](#Spider)

### [Web](#Web)
* [OSI](#OSI)
* [正向代理和反向代理](#正向代理和反向代理)
* [TCP握手协议](#TCP握手协议)
* [GET/POST](#GET/POST)
* [Session、Cookie、Token](#Session/Cookie/Token)
* [HTTP](#HTTP)
* [WSGI](#WSGI)
* [MVC](#MVC)
* [Flask](#Flask)
* [Django](#Django)

### [Database](#Database)
* [事务](#事务)
* [分布式事务](#分布式事务)
* [隔离级别](#隔离级别)
* [一致性哈希](#一致性哈希)
* [缓存穿透、缓存击穿和缓存雪崩](#缓存穿透、缓存击穿和缓存雪崩)

### [Other](#Other)
* [什么是面向过程的程序设计](#面向过程的程序设计)
* [RabbitMQ](#RabbitMQ)
* [负载均衡](#负载均衡)
* [Nginx](#Nginx)
* [LVS](#LVS)



## python
#### list
数据结构：有一个指针数组用来保存列表元素的指针，和一个可以在列表中放多少元素的标记
```
typedef struct {
    PyObject_VAR_HEAD
    PyObject **ob_item;  // 指向列表元素的指针数组
    Py_ssize_t allocated;  // 申请的内存的槽的个数
} PyListObject;
```
python中的list是对其他对象的引用组成连续数组。是一个动态数组，存储在一个连续的内存区块中，
。push和pop操作的复杂度为O(1)，但是插入和删除元素会造成内存块的移动，复杂度为O(n)。

#### dict
###### 解释器赋值：
* a = 'ABC': 解释器做了两件事
    * 在内存中创建了一个'ABC'的字符串对象
    * 在内存中创建了一个 a 的变量，并把它指向了 'ABC' 这个字符串对象
        
把一个变量a的值赋值给另一个变量b，实际就是把变量b指向了变量a所指向的数据
###### 可散列类型：
* 在可散列对象的生命周期中，他的散列值是不变的。需要实现__hash__和__eq__两个方法，
若两个可散列对象是相同的，则散列值一定是一样的
* ```a, b = "123", "".join(["1", "2", "3"])```,则```id(a) == id(b)  # False```，
因为二者已经不是同一对象，也就是```a is b  # False```，但值是相等的，即```a == b  # True```。
散列值/哈希值也是相等的```hash(a) == hash(b)  # True``` 
###### 稀疏数组：
* 所谓稀疏数组就是数组中大部分的内容都未被使用，或者都是零。<br>
数组中仅有少部分空间是有效使用的，因此有一定的空间浪费。

python中dict的底层数据结构是一个散列表，而散列表其实是一个稀疏数组<br>
散列表的里的每一个单元，我们称之为表元。也就是说在dict的散列表中，一个有效的表元其实分为两部分，
一个是对键的引用，一个是对值的引用。<br>
而表元大小一样，故可以通过偏移量来读取每一个表元。
##### 计算方式：
* 计算键的散列值
* 使用散列值中的一部分来定位散列表中的一个表元
    * 表元为空: 抛出异常KeyError
    * 键不相等:
        * 散列冲突
        * 取散列值另一部分来定位
        * 循环
    * 返回表元中的值

由于这种特性，导致字典：
1、键：必须为可散列，是为了能够唯一定位。
2、在空间上开销大：
3、散列冲突会导致字典内无序

#### 函数的参数
包括位置参数、默认参数、可变参数、关键字参数、命名关键字参数
* 位置参数：定义后按顺序传入参数。```def test(x, y, z): ...```
* 默认参数：定义函数时，设定好参数的默认值。```def test(x, y, z="default"): ...```
* 可变参数：允许动态的传入参数。```def test(x, *args): ...```
* 关键字参数：允许动态的传入命名参数。```def test(x, *args, **kwargs): ...```
* 命名关键字参数：限定传入的命名参数。```def test(x, *args, key1, key2): ... ```

#### 高阶函数
一个函数可以接收另一个函数作为参数，或一盒函数返回值为函数，则称之为高阶函数


#### 闭包
当一个高阶函数，返回一个新函数的时候，高阶函数内部的局部变量被新函数引用，这种情况属于闭包。

更详细点就是，函数定义中引用了函数外定义的变量，并且该函数可以在其定义外环境被执行。


#### 装饰器
本质上，装饰器就是一个返回函数的高阶函数。
```
def decorator(func=None):
    def wrapper():
        return func()
    return wrapper
```


#### 偏函数
在python中可通过```functools.partial```来实现。原理就是对于一个已有函数，
通过将某些参数给固定住，从而返回一个新函数。调用这个新函数会更简单。
```
from functools import partial
new_func = partial(int, base=2)
print(new_func('123'))  # default base is 2
```


#### 迭代器
可以用做for循环的数据类型包括：
* 集合数据类型。包括list、dict、tuple、set、str等
* 生成器
可以直接作用于for循环的对象，统称为可迭代对象。Iterable

而可以被next()函数调用并不断返回下一个值的对象，统称为迭代器。Iterator。

可迭代对象可通过iter()函数转化为迭代器。


#### 单例模式
单例模式。在程序生命周期中，确保一个类只有一个实例。
```
class SingleInstance:
    instance = None
    def get_instance(self):
        if not self.instance:
            self.instance = True  # create one instance in here
        return self.instance
```


#### 多线程
首先得从`多任务`操作系统说起。多任务的意思就是：我们边听歌，边打游戏。就用户的感觉而言，
他们是一起执行的，当然后台肯定有其他任务也在一起执行。对于操作系统而言，
一个任务就是一个进程，一个进程，最少拥有一个线程，而线程就是CPU调度的最小单位。

所以线程是进程的一个子任务，多线程也就是进程中多个子任务并发执行。
实际上CPU单次调度只执行一个线程，并发的原理就是操作系统在多个线程之间快速切换，
让每个线程都短暂的交替运行。

python的多线程主要就是使用高级模块threading。而且的python的多线程很有特点。
以CPython为例，他受限于GIL全局排它锁，在某个threading编写多任务程序中，所有的线程，
只能在一个CPU中调度。调度其实是操作系统的事情，全局锁的意思就是，在每次线程切换的时候，
都会上锁。目的是为了保证线程之间数据一致性和状态同步。

因为多线程与多进程最大的不同，就是多进程中每个进程都有自己的一份数据拷贝，相互不影响。
而多线则共享其任务进程的数据资源，这也是GIL全局排他锁存在的原因。


#### 线程本地数据


#### 多进程


#### 协程
协程。我们也可以叫微线程。

在线程中，将每个函数的执行视为一个子程序。多个子程序之间的调用，必然为有序性和层次性。
而且一个子程序调用，总是一个入口，然后对应返回。

例如函数A调用了函数B，函数B中又调用了C，那么顺序为C调用结束后返回，接着B调用结束后返回，
最后才是A执行返回。这种是通过栈结构实现的。

协程不同。同一线程中，不同子程序之间的执行，是可中断的。中断处由开发人员设计，
中断后子程序内部保留既有属性与方法，转而执行其他子程序，在适当的时候在返回中断处继续执行。

异步编程中，最经典的就是异步回调式编程。也就在发生阻塞IO事件时，不进行显示的等待，
只是注册回调事件后转而执行其他程序。当阻塞事件完成后，即可执行已注册事件，继而完成后续的操作。
而协程式异步编程，则没有显示的回调逻辑，则整体编写的代码看上去与同步编程基本上是相同的。
因为协程本身中断后不会影响既有属性与方法，只需要重新激活协程即可继续执行后续代码。

本质上协程式异步编程，也是基于回调式。不过原生库asyncio帮我们封装好了回调逻辑。
将一个协程打包为一个Task任务并添加到期程，返回对应的未来对象。

总体流程就是：
发生IO耗时事件（常见的阻塞IO包括读写IO和网络IO，操作系统将事件分为两类，
也就是可读事件和可写事件）。程序会将此事件注册回调，转而执行其他程序，
当事件状态改变时即会触发回调。

## Spider

## web
web应用的本质。客户端发起HTTP请求，服务端接收请求作出回应，比如生成一个Html文件，
然后服务器把此Html文件作为HTTP响应的Body发送给客户端，由客户端进行后续的显示处理。

#### OSI
从上到下：
* 物理层：
    * 两台硬件之间如何进行通信。具体就是一台发送比特流，另一台接收。
    这就是物理层。更具体点就是通过网线，一台硬件传输1/0转化后的强弱电流，
    另一台硬件接收后再转化为1/0.<br>
    也就是我们常说的数模转化。其中数据是比特。
* 数据链路层：
    * 定义了如何让格式化数据进行传输，以及如何控制对物理介质的访问
* 网络层：
    * 传输层解决了打包的问题。但是多台计算机，A发给F，中间要经过BCD这种
    。如何选择最佳路径呢。这就是路由要做额事情了。
    * 网络层，也就会路由器，交换那些具有寻址功能的设备所实现的功能。
    这一层定义是IP复制，通过IP地址寻址，所以产生了协议。
* 传输层
    * 当需要发送大量数据的时候，需要很长时间。但是由于网络中断，这种
    中断可能是毫秒级别的，这样传输就会存在数据缺失。
    * 于是发送大量文件。需要封装，然后一个一个发送。
    * 如TCP，发出去1w个包，接收方就需要告诉我是否收到了1w包。
    如果缺少了3个包，你告诉我缺了那几个，我再发一次。
    * 如UDP，适合发送少量数据，而且少量数据一般不会丢包。
    在多人游戏中常用UDP协议，一般都是简单的信息传输。如果使用TCP
    效率就会降低，因为会不停的告诉主机我收到了20个包，或者收到了18个包
    再发我两个。效率低。用UDP的话，主机发出去就算了，丢了也算了。
* 会话层
    * 针对用户，总不能让他自己实现TCP打包，IP协议寻址把。
    于是出现了会话层，就是建立与管理应用之间的通信。
* 表示层
    * 不同系统之间语法不一致，如win给mac通信，就可能存在问题。
    * 于是需要表示层，解决不同系统之间通信的语法问题。
* 应用层


#### 正向代理和反向代理
##### 正向代理
正向代理是客户端的代理，也就是客户端通过代理访问服务器，在这个流程中，服务器端只能
知道是代理在访问我，并不知道此次访问的实际作用者是谁。

##### 反向代理
反向代理是服务器端的代理。在客户端访问服务器的过程中，客户端实际接触到的是服务器端的
代理。也就是说并不直接对接服务器，而是由代理进行后续的转发，分配给实际处理的服务器。

#### GET/POST
* GET: 

#### TCP握手协议
总体流程就是客户端发给服务端一个报文，服务端响应此次报文给客户端，客户端再次回应建立连接。
断开的时候，客户端发送。。。
* 三次握手
    * 建立TCP连接的三次握手，在这个过程中总计发送了3个包，目的是为了确保双方的接收能力和
    发送能力是否正常，也指定了自己的初始化序列号为后面的可靠性传输做准备。
    * 实质上，就是客户端连接服务端指定端口，建立TCP连接，并同步连接双方的序列号和确认号，
    交换`TCP窗口大小信息`
    * 初始状态为：客户端处于Closed，服务端处于Listen
    * 第一次握手。客户端给服务端发送一个SYN报文，并指定客户端的初始化序列号ISN。此时客户端进入
    SYN_SENT状态。<br>
    首部的同步位SYN=1，初始化序号sqp=x、SYN=1的报文不能携带数据，但需要消耗一个序号
    * 第二次握手，服务端收到客户端的SYN报文后，会以自己的SYN报文作为应答，并且也是指定了自己的
    初始化序列号ISN，同时会把客户端ISN+1作为ACK值，表示自己已经收到了客户端的SYN，此时服务器
    处于SYN_RCVD状态。<br>
    在确认报文中SYN=1，ACK=1，确认号为ack=x+1，初始序号seq=y
    * 第三次握手，客户端接收到了SYN报文后，会发送一个ACK报文，也是吧服务器的ISN+1作为ACK的值，
    表示已经收到了服务端的SYN报文。服务端接收到ACK后，变更状态并处于ESTABLISHED状态，此时双方
    已建立连接。<br>
    确认报文ack=1，确认号ack=y+1，序号seq=x+1，因为初始化seq=x，所以第二个报文就需要相应x+1，
    有且只有ACK报文可以携带数据，不携带数据则不消耗序号。
    * 发送第一个SYN的一端将执行主动打开（active open），接收这个SYN并发回下一个SYN，
    另一端则执行被动打开（passive open）
    * 第一次握手，是客户端发送网络包，只能确认客户端发送能力是ok的，然后服务端接收了，
    那就确认服务端的接收能力是ok的<br>
    第二次握手，服务端发包，那就确认服务端的发送能力是ok的，客户端接收到了。那就能确认客户端
    接收能力是ok的，至此，可以确认双方的发送的接收能力都是ok的，从我们的角度来看是这样的。
    * 第三次握手，客户端发包，服务端接收，也就代表这个流程已经是ok的。
    * 半连接队列。当服务器第一次接收到SYN的时候，就处于SYN_RCVD状态，此时双方还没有完全建立连接。
    服务器会把此种状态下请求连接放在一个队列中，我们称此队列为半连接队列。<br>
    那么全连接队列就是已经完成了三次握手的socket存放地方。当队列满了就可能出现丢包的现象。
    * SYN_ACK重传次数，服务器当发送完SYN_ACK包后，如果未收到客户端的确认包，服务器会进行第二次
    重传，周而复始，知道重连次数超过最大重传次数，此时会将该连接信息从队列中删除。
* INS（Initial Sequence Number）
    * 当一段建立连接而发送他的SYN时，他为连接选择一个初始序号。ISN随时间而变化，因此每一个ISN都将
    具备不同的ISN。ISN可以看作是一个32比特的计数器，没4ms加一。这样选择序号的目的在于防止网络延迟导致的错误。
    * 三次握手的一个重要功能就是客户端和服务端交换ISN，以便让对方知道接下来接收数据的时候如何按序号组装数据。
    如果ISN是固定的，攻击者很容易猜出后续的确认号。
    * 三次握手中只有最后一次客户端的ACK可以携带数据，其他两次握手不可以携带数据，否则会让服务器更容易被攻击。
    比如在第一次连接中放入大量数据，则会增加服务器的处理时间。
* SYN攻击
    * 服务端的资源分配是在二次握手时分配的，而客户端的资源分配实在完成三次握手时分配的。SYN攻击就是Client
    在短时间内伪造大量不存在的IP地址，并访问Server端，也就是不断的向Server发送SYN包，Server则不停的
    回复确认包，并等待连接。由于源地址不存在，因此Server的确认包不会有响应，但Server仍会不断的重试直至删除。
    这些伪造的SYN长时间的占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络阻塞甚至系统瘫痪。
    * 检查方法就是，在服务器中看到大量的半连接状态，且IP源是随机的时候，基本可以断定是被SYN攻击。
    * 防御方法：1、缩短超时时间。2、增加最大连接数。3、过滤网关防御。4、SYN cookies技术
* 四次挥手
    * 是由TCP的半关闭特性导致的。半关闭的意思就是TCP提供了连接的一端在结束他的发送后还能接收来自另一端
    数据的能力。
    * 四次挥手，也就是总计需要交互四个数据包。双方均可主动发起关闭请求/挥手动作。
    * 第一次挥手，客户端发送一个FIN报文，报文会指定一个序列号。此时客户端处于FIN_WAIT1状态。
    即发出连接释放报文段（FIN=1，序号seq=u），并停止在发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）
    状态，等待服务端确认。
    * 第二次挥手，服务端接收到FIN之后，会发送ACK报文，吧客户端的序列号+1作为ACK报文的序列号值，表明已经
    接收到客户端的报文了，此时服务端处于CLOSE_WAIT状态。
    此时TCP处于半连接状态。客户端收到服务端的确认后，进入FIN_WAIT2状态，等待服务端发出的连接释放报文段。
    * 第三次挥手，服务端准备好了断开连接了，和客户端一样，发送FIN报文，且指定序列号，此时服务端处于LAST_ACK状态。
    此时序列号为seq=w，确认号为ack=u+1，等待客户端的确认。
    * 第四次挥手，客户端收到FIN之后，一样发送ACK作为应答，吧服务端的序列号+1作为自己ACK报文，此时
    服务端处于TIME_WAIT状态，需要过一阵子以确保服务端接收到自己的ACK报文。服务端接收到后就处于CLOSED状态了。
    * 为什么需要四次。在三次握手中，服务端响应时可以直接发送SYN+ACK报文，其中ACK时用来应答，
    而SYN报文则是用来同步的。
    但是关闭连接，也就是服务端接收到FIN的时候时不会立即关闭socket，所以只能先回复一个ACK报文，告诉客户端，你的FIN
    我收到了。只有等到我服务端处理完了socket，才能发送FIN报文。应此不能一起发送。
* 2MSL等待状态
    * TIME_WAIT状态也是2MSL等待状态。每一个TCP实现需要选择一个报文最大生存时间MSL（Maximum Segment Lifetime）
    他是任何报文被丢弃前在网络内的最长时间
    * 目的有两个：
        * 1、保证客户端发送的最后一个ACK报文能够达到服务端。
        * 2、防止已失效连接请求报文出现在本连接中。

#### Session/Cookie/Token
* Session：是一个概念，即信息存储在客户端。（Flask的session是存储在客户端的）
* Cookie：是对Session的一种实现，信息存储在客户端。
* 由于HTTP协议的无状态性，需要识别用户身份时，可以使用到Cookie/Token


#### HTTP
HTTP是一种文本协议，也是常用的网络通信协议。

一次HTTP事件，包含Header和Body。事件通常分为请求事件和响应事件。

* 请求行 - 通用信息头 - 请求头 - 实体头 - 报文主体
* 状态行 - 通用信息头 - 响应头 - 实体头 - 报文主体

请求事件Header中，主要报头和报文。Body是根据请求方式的可选事件
* **GET / HTTP/1.1** 报头包含请求方式、请求路径、协议版本
* **Host: www.google.com** 报文则由Key:Value的结构组成

响应事件Header中，也包括报头和报文，Body就是我们在浏览器中能看到的内容
* **HTTP/1.1 200 OK** 响应报头中包含协议版本、响应状态码、信息说明
* **X-Powered-By: Express** 报文则一样，由Key:Value的结构组成

Header之间以\r\n进行划分，出现两个\r\n\r\n，则后面的数据全为body。

200成功、3xx重定向、4xx客户端异常、5xx服务端异常


#### WSGI
**Web-Server-Gateway-Interface** web服务器网关接口

最简单的web应用就是先把html文件保存好，用先有的HTTP服务器接受用户请求，然后直接返回已有的html文件。
这就是我们常说的静态服务器，如Nginx等。

而实际上一个web应用可能复杂的多，需要我们获取HTTP请求信息并解析，然后做出对应的处理再打包返回。
故为了简化开发，WSGI接口出现了。他实现了对HTTP请求的初步包装，以便web应用进行后续的处理。

一个WSGI接口，封装HTTP请求后，会为web应用提供两个参数，分别为environ和start_response。
* **environ** 此参数是一个dict对象，包含有完整的HTTP请求信息
* **start_response** 此参数是一个函数对象，是用于发送HTTP响应报文的函数

web应用，从WSGI接口中获取这两个参数并进行后续的处理，业务逻辑完成后。
调用且仅能调用一次start_response函数，用于返回响应报文
```start_response("200 fucking", [("Content-Type", "this/is/a/joking")])```，
此函数接受两个参数，第一个是响应报头，里面包含状态码和信息说明。第二个是响应报文，是一个list，
子元素是tuple，tuple内部为两个string，分别对应着报文中的Key:Value
```
from wsgiref.simple_server import make_server
def test_app(environ, start_response):
    start_response("200 fucking-man", [("Content-Type", "text/html")])
    return [b"hello, funking man"]
web = make_server("", 8888, test_app)
web.serve_forever()
```


#### MVC
Model-View-Controller ―― 模型-视图-控制器

python后端代码中，负责处理路由的函数或者类，就是控制器，主要负责业务逻辑

而像jinjia2或Django自带模板框架，里面一些带有{{}}特殊变量的文件，就是视图，主要负责显示逻辑。
也就是通过一些简单的替换，生成最终的显示页面。

而业务逻辑 传递给 显示逻辑 的部分，即是Model模板。本质上是一个字典，也是一个映射表。
作用还是为了渲染视图，生成目标模板

MVC架构，初步拆离了业务逻辑与显示逻辑。


#### Flask


#### Django

## Database

#### 事务
事务就是作为单个逻辑单元执行的一组操作，要么全成功，要么全失败。<br>
这种把多条语句作为一个整体进行操作的功能，称之为数据库事务。
* A-原子性：将所有的SQL作为原子工作单元执行，即要么全执行，要么全不执行。
* C-一致性：事务完成后，所有数据的状态需要一致。
* I-隔离性：多个事务并发执行，每个事务作出的修改必须与其他事务隔离。
* D-持久性：事务完成后，对数据库的修改应该被持久化存储。

对于单条SQL语句，数据库自动将其作为一个事务执行，这种事务被称之为```隐式事务```<br>
而当需要把多条SQL语句作为一个事务执行，则需要使用BEGIN开启一个事务，
使用COMMIT提交一个事务，这种事务被称之为显式事务。
```SQL
BEGIN;
UPDATE account SET balance=balance-100 WHERE id=1;
UPDATE account SET balance=balance+100 WHERE id=2;
COMMIT;
```
当我们希望主动让事务失败，则需要使用ROOLBACK回滚事务，即整个事务会失败：
```SQL
BEGIN;
UPDATE account SET balance=balance-100 WHERE id=1;
UPDATE account SET balance=balance+100 WHERE id=2;
ROOLBACK;
```

#### 分布式事务
单数据源的一致性依靠单机事务来保证，多数据源的一致性就要依靠分布式事务。<br>
* XA分布式事务协议
    * 包含两阶段提交（2PC）和三阶段提交（3PC）
    * 2PC
        * 在XA协议中包含着两个角色：事务的协调者和事务参与者
        * 第一阶段：作为事务的协调者首先会向所有的参与者节点发送Prepare请求<br>
        在接收到请求之后，每一个节点各自执行与事务相关的数据更新，但是不提交事务<br>
        而是向事务协调者返回完成的消息
        * 第二阶段：事务协调者接收到了所有参与者的返回正向消息，则发出commit请求。<br>
        当节点成功commit提交后，会发送确认的消息，至此，整个分布式事务完成。
    * 2PC的缺点：
        * 性能问题：虽遵循强一致性，但事务执行过程中，各节点占用这数据资源<br>
        只有当所有节点准备完毕，事务协调者才会通知提交，然后参与者才会释放资源。
        * 协调者单点故障：协调者单点挂了，基本就无法完成工作。
        * 丢失消息导致不一致：即在第二阶段，发送commit的过程中，某节点未收到消息<br>
        则会导致数据的不一致性。
    * 3PC
        * 在原基础上增加了CanCommit阶段，并引入了超时机制，一旦事务参与者迟迟没有
        接到协调者的commit请求，会自动本地commit。
    * MQ事务：
        * 利用中间件来异步完成事件的后一半更新。
    * TCC事务：
        * 即Try、Commit、Cancel。

#### 隔离级别
##### Read Uncommitted
是隔离级别最低的一种事务级别。在此隔离级别下，一个事务会读到另一个
事务更新后但未提交的数据。<br>
若另一个事务回滚，那么当前事务读到的数据就是脏数据，即Dirty Read<br>

事务A、B
* A：更新了事件但是没有commit，此时B读取到的就是更新后的数据
* B：随后A进行事务回滚，B再度就又得到不同的数据，这就是脏读
总结来说就是：<br>
在Read Uncommitted隔离级别下，一个事务可能读取到另一个事务更新但未提交的数据，这个数据有可能是脏数据

##### Read Committed
在此隔离级别下，一个事务可能会遇到不可重复读的问题。<br>
就是一个事务在两次读取数据的过程中，当有另一个事务同样修改了当前数据，
并且对事务进行了commit。那么前一个事务再次读取就会得到不同数据。

##### Repeatable Read
在此隔离级别下，一个事务可能会遇到幻读Phantom Read。<br>
幻读即，在一个事务中，第一次查询某条记录是发现没有，但是当更新
这条不存在的数据时能够成功密切再次读取同一记录是，能够查询到。<br>

当一个事务进行查询为空时，另一个事务插入了这条数据。然后第一个事务
再次查询结果仍然为空，但是更新这条数据是可以成功的，之后再查就可以出结果。

##### Serializable
Serializable是最严格的隔离级别。在此级别下所有事务按照次序一次执行。
因此脏读、不可重复读、幻读都不会出现。<br>
但是事务的执行是串联执行的，效率会降低。<br>
在mysql的InnoDB引擎，默认的隔离级别是Repeatable Read


#### 一致性哈希
场景描述：<br>
三台服务器，缓存3w张图片，平均每台缓存1w张左右。<br>
如果随机存储，那么访问某个缓存项的时候，就需要遍历所有缓存知道找到目标。
花费时长太多，失去了缓存的意义。缓存本身就是为了提供速度。<br>

* 方法一：
    * 每一张图片名称是唯一的。那么可以对所有的图片名做相同的哈希计算。
    得出的结果应该都是唯一的，然后有3台服务器，我们可以将哈希后的结果
    对3取余，那么余数一定是0-2，正好对应3台服务器。<br>
    如此，下次访问的时候，可以直接计算出图片存在那台服务器上。
    * 此方法有缺陷。当增加/减少服务器的时候，固定的取余数就会出现问题，
    即已有数据和新数据可能对应不上。
        * 问题1：当缓存服务器数量发生变化的时候，会引起缓存雪崩，即可能
        引起整体系统压力过大而崩溃。
        * 问题2：当缓存服务器数量变化时，几乎所有缓存的位置都会发生改变。
* Consistent hashing
    * 将value映射在一个32位的key值中，得到一个环形hash。
    * 对于object，通过哈希算法将其映射到环形hash上。<br>
    对于cache，或者说是redis，同样哈希映射到环形hash上。<br>
    此时，object和cache都映射到了环形hash空间中，接下来顺时针计算，
    object遇到的第一个cache就是目标cache了。
    * 那么此时无论是增加节点还是移除节点，影响的范围应该都是有限的。
    * 问题：hash倾斜
        * hash计算后，分布密集。即存在节点分布不均匀的情况，同样可能会造成缓存雪崩。
    * 解决方法：引入虚拟节点
        * 虚拟节点多于实际cache节点。object会先映射到虚拟节点，然后虚拟节点会再次计算，
        从而映射到实际的cache节点。


#### 缓存穿透、缓存击穿和缓存雪崩
* 缓存穿透
    * 查询一个根本不存在的数据，每次缓存都不会命中，且处于容错考虑，
    如果从存储层查不到数据，则不写入缓存，导致每次请求都要到存储层查询。
    此时缓存就失去了意义。
    * 方法：
        * 直接缓存None值
* 缓存击穿
    * 在高并发情况下，对一个特定的值进行查询，但是该值缓存正好过期，缓存没有命中。
    导致大量请求直接落到了存储库。
* 缓存雪崩
    * 在高并发情况下，大量缓存在同一时间过期，导致大量请求落在数据库上。
    * 方法：
        * 缓存预热：即设定过期时间和预加载时间，每次缓存获取时都会计算
        达到预加载的时间，达到了则异步更新缓存。

## Other

#### 面向过程的程序设计
函数是编程语言通用的一种封装，通过将大段代码拆分为函数，通过一层一层的函数调用，
就可以把一个复杂任务拆分为多个简单任务，这种分解就是面向过程的程序设计。
而函数就是面向过程的程序设计的基本单元。

#### RabbitMQ
* broker: 消息队列服务器实体
* virtual host: 虚拟主机。默认vhost为/，每个vhost本质上就是一个mini版的rabbitmq服务器，拥有自己的队列、交换器、绑定和权限机制。可以理解为是一个自己的账号。
* exchange: 交换器，用来接收生产者发送给消费者的消息，并将这些消息路由给服务器的队列
* queue: 消息队列，用来保存消息知道发送给消费者。是消息的容器，也是消息的终点。一条消息可投入一个/多个队列。期间消息一直在队列中，等待消费者连接这个队列并取走。
* banding: 绑定，用于消息队列和交换机之间的关联。一个绑定就是基于路由键将交换机和消息队列连接起来的路由规则，所以可以将交换器理解为一个由绑定构成的路由表。
* channel: 信道，多路复用连接中的一条独立的双向数据流通道。因为对于操作系统而言，建立和销毁TCP都有一定开销，故引入信道概念，复用一条TCP。<br>
amqp命令都是通过信道发出去的，如发布消息、订阅消息、或者或者是接收消息。
* connection: 网络连接。如TCP连接
* publisher: 消息生产者，可以使一个向交换器发布消息的客户端应用程序
* consumer: 消息消费者，从某消息队列取得消息的客户端应用程序
* message: 消息，消息不具名，由消息头和消息体组成。消息头由一系列可选属性组成，<br>
包括routing-key（路由键）、priority（优先级）、delivery-mode（消息可能需要序列化存储【消息的理由模式】）

exchange类型<br>
* direct: 消息中的路由键（routing-key）如果和binging中的binding-key一致。交换器就将消息队列发到对应的队列中。即路由与队列名完全匹配。
* fanout: 交换器的消息会分发到所有绑定的队列中。fanout交换器不处理该路由键，只是简单的将队列绑定到交换器上，<br>
每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。fanout类型转发消息最快。
* topic: topic交换器通过模式匹配分配消息的路由属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。<br>
识别两个通配符#*，#匹配多个单词，*则匹配一个单词。


#### 负载均衡
* HTTP重定向
    * 通过web服务器中的Location报文头，指向真正的工作服务器
* DNS负载均衡
    * 域名与IP相互映射到一个分布式数据库。通过域名，得到对应IP地址的过程叫做域名解析。
    而且是可以为多个不同的IP地址配置同一个域名。
    * DNS服务器充当主站点，将用户请求的域名映射为实际的IP地址，这种映射是可以一对多。
    * 在DNS服务器中，可以为多个不同的地址配置同一个域名，而最终查询这个域名的
    客户机将在解析这个名字时得到其中的一个地址。故同一个域名客户机可能会得到不同的地址。
    * 缺点：
        * 负载分配不均匀：DNS服务器将HTTP请求平均的分配到后台的服务器上。
        而不考虑每一台服务器的负载情况；如果后台的web服务器的配置和处理能力不同，
        则最慢的web服务器将成为系统的瓶颈，处理能力强的服务器则不能充分发挥作用。
        * 可用性低：如果后台某台web服务器故障，DNS服务器仍然会将请求分配到故障机上，
        导致无妨正常响应客户端。
        * 变更时间长，如果更改DNS有可能造成相当一部分用户无法正常访问web服务器。并且由于
        DNS缓存的原因，所造成的后果需要持续相当长的一段时间，一般为24小时。
* 反向代理
    * 反向代理的核心就是转发HTTP，任何实际服务器的HTTP请求都需要经过调度器，而调度器
    则等待实际服务器的HTTP响应，并将之反馈给用户。
* 基于四层交换技术的负载均衡
    * 代表：LVS、F5
    * 通过修改报文中的目标地址和端口，也就是将负载均衡所在服务器的地址，改为后端服务器IP地址，
    这样用户的请求就可以直接跟后端服务器建立TCP连接并发送数据。
    * 优点：性能高、支持各种网络协议。
    * 缺点：对网络依赖较大，负载智能化方面没有第七层负载好。比如不支持对url的个性化负载。
* 基于七层交换技术的负载均衡
    * 代表：nginx
    * 也叫内容交换，主要通过传递报文中真正有意义的应用层内容来实现。起一个反向代理的作用。
    客户端需要先于七层负载设备进行三次握手建立TCP连接，把套访问的数据报文信息发送给七层均衡负载；
    然后七层均衡负载再根据适当的规则选择web服务器，建立TCP连接，将数据发送给他进行处理。最后数据还是返回
    给七层均衡负载，负载均衡设备再把数据发送给client。
    * 缺点：性能没有4层负载高
    
#### Nginx
主要作用就是反向代理和负载均衡。<br>
* Nginx集群
    * 一般当Nginx作为外部唯一访问入口的时候，没有办法以集群的时候对外提供服务。<br>
    客户端的每一次请求，都需要先与nginx所在服务器建立TCP连接，并将相关报文信息传递，<br>
    之后由nginx所在服务器进行负载均衡分配，选择对应的web服务器，并将用户请求信息进行转交<br>
    * 一台nginx理论上最大并发应该在5w左右，即使是keepalived+nginx，实际上也只有一台机器在工作<br>
    面对更大并发的时候，就需要在其之上在加一层负载均衡器。

#### LVS
Linux Virtual Server，也就是linux虚拟服务机，是一个虚拟的服务器集群系统。
实现的三种方式：
* DR：direct route 直接路由
    * 请求有LVS接收，有真实提供服务的web服务器（RealServer，RS）直接返回给用户，返回的时候不仅过LVS。
    * DR模式下，要求LVS服务器与RS绑定在同一个VIP，一个请求发过来的时候，只需要将网络帧的MAC地址，<br>
    修改web服务器所在的MAC地址，该包就会被转发到响应的RS处理。<br>
    此时的源IP与目标IP都没有改变。RS接收到LVS转发过来的包，发现MAC是自己，IP地址也是自己，<br>
    于是就认为这个包是合法的，当RS返回请求的时候，只需要向源IP直接返回即可，不需要经过LVS。
    * 可以理解为转发了TCP的第一次握手?
    * 优点：性能非常高
    * 缺点：要求负载均衡服务器与RS在同一个物理字段。
* NAT：Network Address Translation网络地址转换
    * 是一种外网和内网地址映射的技术，在NAT模式下，LVS需要作为RS的网关。在网络包到达LVS的时候，<br>
    LVS做目标地址转化（DNAT），将目标IP改为RS的IP，<br>
    当RS接收到包之后，处理完，返回响应时，源IP是RS的IP，目标IP是客户端IP，这时RS的包通过网关LVS
    进行中转，此时LVS会做源地址转化（SNAT），将包的地址改为VIP，对于客户端，就只知道是LVS直接返回
    给他的了。
    * 缺点：LVS-NAT模式，请求和响应都需要经过LVS，性能没有DR模式好。
* TUN：tunnel 隧道
    * 通过IP隧道减轻LVS调度服务器的压力。一般的网络请求都是请求包很小，但是响应比较大，<br>
    负载均衡只负责把请求分发给物理服务器，而物理服务器将应答包直接发送给用户。所以负载均衡器能
    处理巨大的请求量，相比NAT性能好很多。<br>
    比DR模式的优点是不限制负载均衡器与RS在同一个物理段。
* 集群优化之路：
    * 首先是nginx负载，客户端需要先与nginx所在服务器进行TCP连接，然后由nginx所在服务器转发数据<br>
    所以理论上nginx最大并发量会被限制在5w+
    * 此时需要在nginx的上游做处理，引入LVS。若有LVS和nginx都在同一网段，那么可以直接使用DR模式<br>
    当LVS接收到请求时，直接修改此次请求的MAC地址，再转给负载均衡的RS，相当于直接转TCP的第一次握手<br>
    这种情况下，客户端直接与RS建立了TCP连接，进行直接的交互。<br>
    或者还可以使用NAT模式，也就是网络地址转化，此时LVS直接作为nginx集群服务器的网关，<br>
    每次当接收请求是，将请求的目标地址转化为RS所在服务器的IP地址，进行转发。服务器响应后<br>
    会直接返回数据，但是由于LVS处于网关位置，会接收到来自服务器的响应，此时再将源地址，改为VIP地址<br>
    对于客户端来说，该次请求还是LVS直接返回的。但是这种模式，LVS会存在一定的性能问题，一般的请求中<br>
    请求包的数据都是比较小的，而响应包就比较大，所以网络链路可能会是一个问题。<br>
    此时可以使用TUN，也就是ip隧道，此时LVS只负责将请求分发下去，而对应的服务器，接收请求后会直接
    发送给用户，相比NAT性能又好一些。
    * 当数据链路都是问题的时候，可以尝试从DNS负载均衡入手，也就是域名解析了。<br>
    可以使用LVS+keepalived来保证LVS的高可用性，但是这种还是只有一台服务器在工作<br>
    可以使用DNS负载均衡，对主备两台机子都有机会轮训使用。即使有一台服务器宕机，<br>
    还是可以使用另一台服务器。
    * 总体来说LVS还是存在一定的瓶颈。这是可以考虑LVS-ospf集群，<br>
    此种方法需要第三层交换机设备来实现。<br>
    或者使用多组双组结构来实现LVS的集群也是可以的。需要每台LVS都绑定一个vip（公网IP）<br>
    而DNS则设置为域名轮询多个IP，实现高并发高可用。
